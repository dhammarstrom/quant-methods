---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Categorical predictors and multiple regression

We have up to now used a single continuous predictor to predict a dependent variables. We will now show that the ordinary regression models can be extended and modified to perform statistical tests such as the *t*-test. This will show that the ordinary regression model is very flexible.

## Linear models can be used instead of t-tests
*t*-test are designed to compare means. A question you might want to answer using a *t*-test is how unlikely the results from your test is if there were no true differences between values from two groups (independent *t*-test), or two samples from the same individuals (paired sample *t*-test) or comparing a group to a specific value (one sample *t*-test). Another way of describing these tests are; tests of differences from zero in a one-sample case or differences between groups with paired or unpaired observations.

Using the `cyclingstudy` data set we can perform *t*-tests. In the code below we will select the variable squat jump and filter it from two time-points. `pivot_wider` is used to put squat jump performance from the two time-points in separate columns. A change score is then calculated.  

```{r}
#| eval: true
#| warning: false
#| message: false


library(tidyverse)
library(exscidata)


cyc_select <- cyclingstudy %>%
  # select a subset of variables, squat jump max is the outcome of interest.
        select(subject, timepoint, sj.max) %>%
  # time-points of interest
        filter(timepoint %in% c("pre", "meso3")) %>%
  # spread the data based on time-points
        pivot_wider(names_from = timepoint, 
                    values_from = sj.max) %>%
  # create a change score
        mutate(change = meso3 - pre) 


```

The data above may be used to perform the paired sample t-test, or one sample t-test. These are basically equivalent. In the first case we use both vectors of numbers and test if the difference between them are different from zero. In the other case we calculate the differences first and then test if the mean *change-score* is different from zero. In the paired sample *t*-test, the argument `paired = TRUE` must be added to the `t.test`call to make sure you do a paired comparison. In the one-sample case we have to set the mean we want to compare to, in this case zero (`mu = 0`).

```{r}
#| eval: true
#| warning: false
#| message: false


paired <- t.test(cyc_select$meso3, cyc_select$pre, paired = TRUE)
one_sample <- t.test(cyc_select$change, mu = 0)



```

These tests are equal as we can see from the comparison below. They are also equivalent to a linear model where we simply model the mean of the change score. When fitting the `change` variable without any predictors we estimate a single parameter in our model, the intercept. The intercept coefficient can be used to test against the same null-hypothesis (change not different from zero), the same results will appear. We can add all result to the same table (@tbl-model-comp).

```{r, eval = TRUE}
#| eval: true
#| warning: false
#| message: false
#| label: tbl-model-comp
#| tbl-cap: "Comparing a paired sample t-test, one sample t-testa and a linear regression model"

linear_model <- lm(change ~ 1, data = cyc_select)

 
library(gt)

data.frame(test = c("Paired sample t-test", "One sample t-test", "Linear model"), 
           t.value = c(paired$statistic, one_sample$statistic, coef(summary(linear_model))[1, 3]), 
           p.value = c(paired$p.value, one_sample$p.value, coef(summary(linear_model))[1, 4]), 
           estimate = c(paired$estimate, one_sample$estimate, coef(summary(linear_model))[1, 1]), 
           lwr.ci = c(paired$conf.int[1], one_sample$conf.int[1], confint(linear_model)[1]),
           upr.ci = c(paired$conf.int[2], one_sample$conf.int[2], confint(linear_model)[2]),
           se = c(paired$stderr, one_sample$stderr, coef(summary(linear_model))[1, 2])) %>%
  tibble() %>%
  
  gt() %>%
  fmt_auto() %>%
  cols_label(test = "Test", t.value = md("*t*-value"), p.value = md("*p*-value"), estimate = "Estimate", lwr.ci = "Lower CI", upr.ci = "Upper CI", se = "Standard error")
  

```

We can also test if there is a true difference in `VO2.max` change between group `INCR`and `DECR` using a t-test.

```{r}
#| eval: true
#| warning: false
#| message: false

cyc_select <- cyclingstudy %>%
  # Select appropriate variables and filter time-points
        select(subject,group, timepoint, VO2.max) %>%
        filter(timepoint %in% c("pre", "meso3"), 
               group != "MIX") %>%
  # make the data set wider and calculate a change score (%-change).
        pivot_wider(names_from = timepoint, 
                    values_from = VO2.max) %>%
        mutate(change = meso3-pre) %>%
        print()


# Perform a two-sample t-test
t.test(change ~ group, data = cyc_select, var.equal = TRUE)

```

Above we use the formula method to specify the *t*-test (see `?t.test`). `var.equal = TRUE` tells the `t.test` function to assume equal variances between groups.

The same result will appear when we fit the data to a linear model. The `summary` function is a generic function, meaning that many type of R objects has summary methods. From `summary` we get a regression table of estimates. The first row is the intercept, we can interpret this as the mean change in one of the groups (`DECR`). This rows has all the statistics associated with this estimate including the average (Estimate), standard error, *t*-value and a *p*-value. 

The second row represents the difference between groups. The `INCR` group has a change score that is 164.8 units larger than the `DECR` group. The associated statistics can be used to assess if this difference is large enough to declare surprisingly large if the null hypothesis is actually true.

```{r}
#| eval: true
#| warning: false
#| message: false


lin_mod <- lm(change ~ group, data = cyc_select)

summary(lin_mod)

```

If you compare the two tests, do they tell you the same?

Using `var.equal = TRUE` in the unpaired *t*-test we assumed that the variation was similar in both groups. This might not be the case, and R uses the Welch two-sample *t*-test by default which does not assum equal variance between groups. Even the Welch two sample t-test can be replicated using a linear model. However, we have to specify it in a slightly different framework using the `gls()` function from the `nlme` package.  

```{r, eval = FALSE}
library(nlme)

welch_twosample <- t.test(change ~ group, data = cyc_select, var.equal = FALSE)

lin_mod_var <- gls(change ~ group, data = cyc_select, weights = varIdent(form = ~1|group), na.action = na.exclude, method = "ML")


welch_twosample
summary(lin_mod_var)

```

You are not required to master `gls` at this time. It however shows that the linear model frame work is very flexible as it in this case also can be adjusted to take care of heteroscedasticity. 

## Dummy variables

The group variable that we used in the code above introduces something new to the linear model, namely dummy variables. When we put a categorical variable in the `lm` command, R will code it as a dummy variable. This variable will be zero if the group corresponds to the first level of the categorical variable (coded as a factor variable) and it will be 1 if it is the second level.

In the simplest case (as above) we will get a linear model looking like this:

$$Y = \beta_0 + \beta_1X$$

Where the $X$ is the grouping variable, remember, 0 if first (reference) group and 1 if the second level group. The coefficient $\beta_1$ only kicks in if the group is 1. Meaning that when group = 0 we have only the intercept. If group = 1 we have the intercept + the slope. The slope represents the difference between the intercept (group = 0) and group = 1.

If the grouping variable would have more groups more dummy-variables would have been added. 

Using all groups in the data set, fit a model and interpret the results.

 <a id="displayText" href="javascript:toggle(2);">Here is a possible solution</a>
  <div id="toggleText2" style="display: none">

```{r, eval = FALSE}
cyc_subset <- cyclingstudy %>%
        select(subject,group, timepoint, VO2.max) %>%
        filter(timepoint %in% c("pre", "meso3")) %>%
        pivot_wider(names_from = timepoint, 
                    values_from = VO2.max) %>%
        mutate(change = 100 * (meso3-pre)/pre) %>%
        print()

mod <- lm(change ~ group, data = cyc_subset)

summary(mod)

```

The `DECR` group is the reference group, the intercept shows the mean of this group. Each parameter shows the difference from the reference.



  </div>
  </br>  

The same assumptions are made with these kinds of models and they can be checked with the same methods as described above. 

## Multiple regression

Contrary to the *t*-tests used above, the linear model can be extended by adding predicting variables (independent variables). In a situation where multiple independent variables are included in the model, we control for their relationship to the dependent variable when we evaluate the other variables. Similarly with univariate regression we can examine each individual parameter from the summary.

In a previous example we used `height.T1` to predict `VO2.max`. We might want to add information to the model. We might wonder if the age (`age`) of participants have a relationship with VO~2max~. To fit this model, use the code below.

```{r, eval = FALSE}

cycling_data <-  cyclingstudy %>%
       # select(subject, timepoint, VO2.max, weight.T1, height.T1) %>%
        filter(timepoint == "pre") %>%
        print()  
          

mod1 <- lm(VO2.max ~  height.T1 + age, data = cycling_data)

summary(mod1)

```

From the output we can see that there is a negative relationship, when age increases VO~2max~ decrease. We can compare this model to the simpler model by looking at the $R^2$ value. We fit the simpler model.

```{r, eval = FALSE}

mod0 <- lm(VO2.max ~  height.T1, data = cycling_data)

summary(mod0)

```

We can interpret $R^2$ as the percentage of the variation explained by the model. When we added more variables to the model we add information that collectively explain a larger portion of the observed data. When adding variables we face the risk of over-fitting our model. With enough variables the model will explain the observed data with less and less uncertainty, however, new data will probably not validate the model.  

The same assumptions apply to the multiple regression model as with the univariate regression model. We have to take care that we have homoscedasticity, independent observations and normally distributed errors. 




# Introduction to data science

## About data in the world of sport and exercise

Data are everywhere. Most of us walk around with a data collection device in our pockets all the time. This device (your mobile phone), records and store data about you all throughout the day. Such data are the basis of the *quantified self movement*[^1] that have grown in popularity as capabilities to record data from daily life has become better. People interested in quantifying their personal life does so for different reasons, but often with the intent to improve their health[^2]. 

[^1]: Read more about the quantified self movement [in this Wikipedia article](https://en.wikipedia.org/wiki/Quantified_self) 

[^2]: See this website for [intriguing examples](https://quantifiedself.com/show-and-tell/)

Much of these kind of data are readily available to us due to the fact we are protected by data privacy policies and regarded as personal data[^3]. With some effort you yourself can get your data out of your iphone to explore, for example, your daily step count. I discovered that my phone(s) has been collecting data for me since 2016 and I tend to walk less steps on Sundays compared to Saturdays (see Figure \@ref(fig:iphone-data)).

[^3]: See e.g. [Apples Privacy Policy](https://www.apple.com/legal/privacy/en-ww/).

```{r iphone-data, fig.align='center', fig.height=8, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Step count data from my iPhone displayed as all avalable data points (A, after data cleaning) and average step per weekday, per year and season (B)."}


library(tidyverse)
library(lubridate)
library(cowplot)


steps <- read_csv2("./data/steps.csv") %>%
  
  mutate(start = dmy_hm(Start), 
         finish = dmy_hm(Finish)) %>%
  

  dplyr::select(start, finish, steps = `Steps (count)`) %>%

  mutate(
    date = format(start, '%Y-%m-%d'),
    month = format(start, '%m'),
    span = (as.numeric(finish - start)/60)/60,
         
         year = format(start, '%Y'), 
         day_of_week = weekdays(start), 
         season = if_else(month %in% c("01", "02", "12"), "Winter", 
                          if_else(month %in% c("03", "04", "05"), "Spring", 
                          if_else(month %in% c("06", "07", "08"), "Summer", 
                          "Autumn")))) %>%
  
  # Remove records that span more than 9 hours
  filter(span < 9) 


steps_fig1 <- steps %>%
  mutate(date = ymd(date)) %>%
  filter(steps < 10000) %>%
  
  ggplot(aes(date, steps)) + geom_point(shape = 21, fill = "blue", alpha = 0.4) + 
  scale_y_continuous(limits = c(0, 2000)) +
  labs(y = "Step (counts)", 
       x = "Date") + 
  theme_minimal()



steps_fig2 <- steps %>%
  group_by(year, day_of_week, season, date) %>%
  summarise(steps = sum(steps)) %>%
  
  group_by(year, day_of_week, season) %>%
  summarise(steps = mean(steps)) %>%
  
  
  mutate(day_of_week = if_else(day_of_week == "mandag", "Monday", 
                               if_else(day_of_week == "tirsdag", "Tuesday",
                                       if_else(day_of_week == "onsdag", "Wednesday",
                                               if_else(day_of_week == "torsdag", "Thursday",
                                                       if_else(day_of_week == "fredag", "Friday",
                                                               if_else(day_of_week == "lørdag", "Saturday","Sunday")))))),
         day_of_week = factor(day_of_week, levels = c("Monday",
                                         "Tuesday", 
                                         "Wednesday",
                                         "Thursday",
                                         "Friday",
                                         "Saturday",
                                         "Sunday")), 
         season = factor(season, levels = c("Winter", "Spring", "Summer", "Autumn"))) %>%
  
  filter(year != "2016") %>%

  ggplot(aes(day_of_week, steps, group = year)) + geom_line() + facet_grid(year ~ season) + 
  
  labs(y = "Average steps per day", 
       x = "Day of the week") + 
  scale_x_discrete()+ 
  theme_minimal() +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))
  
  
  plot_grid(steps_fig1, 
            steps_fig2, ncol = 1, 
            rel_heights = c(0.5, 1), 
            labels = "AUTO", 
            label_size = 12)


```

Data are also collected and stored in publicly available databases. Such databases are created for the purpose to store specific types of data, such as soccer[^4] or biathlon results[^5], or biological information such as gene sequences[^6]. Even data from scientific studies are now days often publicly available[^7] meaning that we can perform scientific studies on unique data sets without collecting the data ourselves. 

[^4]: [understat.com](https://understat.com/) stores match specific data from major leagues. Data are available through software packages such as [`worldfootballR`](https://jaseziv.github.io/worldfootballR/index.html)

[^5]: [biathlonresults.com/](https://biathlonresults.com/) hosts results from the international biathlon federation. An example of analyzed data can be [seen here](https://sciathlon.github.io/post/biathlon_data_analysis/).

[^6]: [Ensembl](https://www.ensembl.org/) and the [National center for biotechnology information](https://www.ncbi.nlm.nih.gov/) are commonly used databases in the biomedical sciences.

[^7]: We published our raw data together with a recent paper (Mølmen et al 2021 [doi: 10.1186/s12967-021-02969-1.](https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-021-02969-1)) together with code to analyze it in a [public repository](https://github.com/dhammarstrom/rnaseq-copd).

The above examples shows that there are abundance of data around and available to us. The problem is that in order to understand a phenomena better, we need techniques and methods to make sense of the data. This is where data science and data literacy comes in. In the world of sport and exercise, regardless if you are interested in doing scientific investigations, coach a soccer-team or individual athletes or help patients recover from surgery using exercise therapy, you are faced with the problem of handling and make sense of data. Some of the key skills and deeper understanding about data science are very much transferable between such areas of practice.  

> **Think about the literature!**
  Spiegelhalter (The Art of Statistics, in the introduction chapter) talks about how statistics has evolved towards the broader field of data science. In data science, statistical theory and methods are just parts of the problem solving cycle. Try to think about how you would use the PPDAC cycle as a exercise coach and a scientist. What are the similarities and differences?

One broader aim of this course is for you to develop skills to better understand data.

## Replication and Reproducibility

In scientific research, replication is a way to confirm scientific claims. When a result can be confirmed by an independent group of researchers, the claim is  more likely to be true. Many results will however never be possible to replicate due to the size of trials, costs and urgency of the research question. A recent example could perhaps be the many vaccine trials performed to develop a vaccines against COVID-19[^8]. Other examples concern studies with unique study populations, such as large scale epidemiological studies [@RN1492], but the same could be said to be true for unique investigations in sport and exercise science.  

[^8]: https://www.evaluate.com/vantage/articles/news/snippets/its-official-covid-19-vaccine-trials-rank-among-largest

When studies are not likely to be *replicated*, *reproducibility* of the analyses and results has been suggested to be a minimum standard for scientific studies. Reproducibility means that given the same data, similar results or conclusions can be drawn by independent researchers [@RN1492].

Peng et al. [@RN1492] suggests that a *fully reproducible* study has 

- Available data.
- Computer code (software) that produces the results of the study.
- Documentation that describes the software and data used in the study, and
- ways to share the data and code.

The above principally relates to the trust we can place in scientific results. However, the minimum standard of reproducibility has advantages also for the individual researcher (or master student)! When working with reproducible methods we will develop ways of documenting and automating our analyses. This will make it easier to collaborate with others. And, as it turns out, your most frequent collaborator is you, in the future!

A reproducible data analysis means that you will make it explicit and transparent. In a traditional data analysis, most activities are in the "black box". In order to avoid bias [@RN1953], the "black box" needs to be opened and you need to actively make transparent decisions all along the analytic pipeline [@RN1955]. This pipeline preferably involves the whole problem solving cycle described by Spiegelhalter [@RN2902]. However the tools that we will learn about in this course focuses primarily on the steps from the experimental design to presentation of statistical results [@RN1955]. These steps includes data collection (and storage), data cleaning, exploratory data analysis, statistical modelling and statistical inference (and communication) [@RN1955].

## Tools in data science

Ways to interpret and make sense of data involves different methods. These methods are now days often implemented in computer software. This means that when you as a practitioner (scientist, coach, analyst...) want to understand data, you have to master some kind of computer software. The most common software used to understand data is probably Microsoft's Excel. You can do amazing stuff with Excel! In the world of sport and exercise Excel has been used in such diverse activities such as scientific investigations, planning and recording training for Olympic medalists[^9] and scheduling appointments.

[^9]: The amount of time used by different coaches to create their own specific coaching software really makes many of them amateur software engineers. See for example this training journal from [swedish orienteering](http://obasen.orientering.se/traningsdagbok/installationshandledning.htm).

For scientific research, most people use additional software to do statistical analyses. If you have spent time in higher education you have probably heard about SPSS, Stata or Jamovi. These are all specialized software used for statistical analyses.

The above mentioned tools can all be used as part of a fully reproducible workflow. However, there are software solutions that actually suits this requirement better than others. Going back to the description of reproducible science as made by Peng et al. [@RN1492], we want software where analyses can be 

- Human- and computer-readable, meaning that we want to be able to write scripts, or computer programs that execute the analyses.
- Documented, meaning that along the code we want to be able to describe what the code does.
- Available and able to share with other, meaning that we analyses can be run on open and free software to maximize ability to share them.

This means that the software that we would prefer should be run using scripts (as opposed to point and click) and be free of charge (and open source, as opposed to expensive and proprietary). These criteria can be fulfilled when we use software that is written around the R language (although alternatives exists[^10]).

R is a computer language that is especially well suited for reproducible data analysis. As users are able to contribute software extensions, also called packages, many specialized software implementation exists for different tasks, such as creating figures or analyses of specific data. Around R, people have been developing auxiliary software to enable reproducible data analysis. The negative part of all these opportunities is that using R requires some effort. The learning curve is steep!

Even though you might not use R ever again after this course, making and effort trying to learn it will let you know something about programming, capabilities of modern data science, statistical analysis and software/computers in general. These areas are all aspects of our modern society and are very much transferable regardless of what computer language we are talking about.

A big challenge when working with complex analyses or other large projects over time is keeping track of changes. Another challenge might be effective collaboration, with others and with yourself in the future. To overcome these challenges we can use a version control system that is connected to a social platform for distributing computer code and data. Github is a web-based platform that does provides this functionality. It is a very powerfull combination if you want to be able to collaborate and share what you are working on.  


[^10]: In addition to R, Python offers a free open source environment for reproducible analyses. The choice between the two are [matter of taste](https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis).

## Installing and getting to know the required software

As noted above, there are multiple computer languages and software solutions that could satisfy our needs. However, in this course we will focus on a combination of tools that continuously are improved to make it easy for the user to collaborate and communicate data analyzes. Below is a checklist of what you need to have installed on your system to take full advantage of the proposed tools.

### R and RStudio

R is a free, [open-source](https://en.wikipedia.org/wiki/Open_source) software designed for statistical computing. We will use R as a part of an environment (using R Studio, introduced below). To download and install R:

1.  Go to <https://cran.uib.no/>,

2.  Select your operating system (Download R for Windows, MacOS or Linux).

    -   If you have Windows, choose `base`, click on "Download R (...) for windows", save and run the file. The installation process should be self explanatory.
    -   If you have MacOS, download and install the latest release.
3. Run the installer to install R.



[RStudio](https://www.posit.co/) is a software designed to make it easier to use R. It is free to download and use. It is designed as an **integrated development environment** that lets you organize your work together with R and other tools. Install it by going to <https://www.posit.co/>.

1.  Select "Products" and **RStudio IDE**
2.  Scroll down and find the [FREE open source edition](https://posit.co/downloads/)
3.  Download the installer made for your operating system.


### Git and Github

Git is a software that you need to install on your system in order to use version control. Github is the web platform that allows collaboration and web-based storage of your work. First we will install git.

1. Go to [https://git-scm.com/downloads](https://git-scm.com/downloads) and download the latest version for your operating system. 
2. Run the installer. Make a note of where you installed it!

3. To let RStudio know where git is located we need to open RStudio, go to *Global Options* under the *Tools* menu. Go to the *Git/SVN* sub-menu and find the **folder where git.exe** is located by browsing in the *"Git executable"* field.

To registrer for a Github account

1. Go to [Github.com](www.github.com).
2. Find "Sign up" and follow the instructions.


#### Git and clients

As noted above, git is a software containing a number of functions for version control of files collected in a folder (or repository). A client in this context refers to a *user interface* that makes it easy to communicate with git. RStudio has some features that makes it possible to execute git commands by clicking, however this *client* is not very powerful, you might want another, or several other alternatives.

First, git is available from the command line. It might look like this:

```{code}
#| eval: false

> git add -A

```

We will touch upon more git commands for the command line later. The above adds all changes you have made to a list of changes that will be included in your next snapshot of your project. More on that later.

Several Git clients can be run at the same time. This means that you might do some git on the command line in a terminal window in RStudio, and you might follow the changes in a graphical user interface, such as [GitHub Desktop](https://desktop.github.com/). The graphical user interface lets you navigate more easily and might help you understand what git is doing. We will be using GitHub desktop, so you might want to install it!

1. Go to [desktop.github.com](https://desktop.github.com/)
2. Download the installer and follow the instructions.


### Quarto and friends

The R community has pioneered literate programming for data analysis by early adoption of file formats that lets the user combine computer code and output with text [@RN1492]. A well adopted file format i recent years have been [R markdown](https://rmarkdown.rstudio.com/) which combines R code with text and lets the user compile reports in multiple output formats from a source document. R markdown is an "R-centric" approach to literate programming. Even though it lets you combine multiple computer languages, all code execution goes through R. Recently, a new format has been introduced, [Quarto](https://quarto.org/), which is not built through R but through a dedicated software, Quarto. 

Rmarkdown and Quarto have many similarities in that you can use markdown, a well established [markup language](https://en.wikipedia.org/wiki/Markdown) to edit text with plain text. This means that for the R user, most differences in formatting your documents are irrelevant for getting started.

As quarto authoring requires its own software, we need to do some installation.

1. Go to [quarto.org](https://quarto.org/)
2. Click "*Get Started*" and follow the instructions. 

A nice output from a quarto source document in a PDF. In order to create PDFs using R/RStudio/quarto we need to install a version of the typesetting system [TeX](https://en.wikipedia.org/wiki/TeX). Quarto recommends[^11] using [tinytex](https://yihui.org/tinytex/) which is easilly istalled after you have installed quarto.

1. Open up RStudio and a fresh terminal
2. type `quarto install tinytex` and follow the instructions. 

You should be ready to go now!

[^11]: See the quarto documentation for details on creating pdfs and installing TeX distributions https://quarto.org/docs/output-formats/pdf-basics.html


## Summing up and where to find help

We have installed R, RStudio, git, quarto and tinytex. You have also created a github account. These are the tools that you will need to go further in this course. But what if you run into problems? Do not worry, the internet is at your service!

Learning new skills, like doing data analysis by programming, can be hard but rewarding. If you want to make your learning experience less hard, consider these points:

- **There are (almost always) multiple solutions to a problem**. When faced with difficulties, do not give up trying to search for a perfect single solution. Instead know that there are multiple ways of defining the problem and therefore multiple solutions.
- **Someone else has already had the same problem**. The internet is full of questions and answers, also related to what ever problem you might have. Learning how to write "googleable" questions is a great skill. By adding "in R" to your problem in a google search term often helps finding R related solutions.
- **Find your motivation**

### A list of reference material and resources


- [R for Data Science](https://r4ds.hadley.nz/) is a very comprehensive guide to working with R. It can be used chapter by chapter or by looking for tips on specific subjects. 

- [Happy Git and GitHub for the useR](https://happygitwithr.com/index.html) is used as background material for our workshop in version control and collaborative data analysis.

- [Stack overflow](https://stackoverflow.com/) is a web platform where users provide answers to questions raised by other users. Here you will find answers to many of your R-related questions. Stack overflow will likely come up if you google a R problem by you can also search the website.






































## References

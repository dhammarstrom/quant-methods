# Introduction to data science

## About data in the world of sport and exercise

Data are everywhere. Most of us always walk around with a data collection device in our pockets. This device (your mobile phone) records and store data about you throughout the day. Such data are the basis of the *quantified self-movement*[^1], which has grown in popularity as capabilities to record data from daily life have improved. People interested in quantifying their personal life does so for different reasons, but often with the intent to improve their health[^2]. 

[^1]: Read more about the quantified self movement [in this Wikipedia article](https://en.wikipedia.org/wiki/Quantified_self) 

[^2]: See this website for [intriguing examples](https://quantifiedself.com/show-and-tell/)

Much of this kind of data is readily available to us because data privacy policies regard it as personal [^3]. With some effort, you can get your data out of your iPhone to explore, for example, your daily step count. I discovered that my phone(s) has been collecting data for me since 2016, and I tend to walk fewer steps on Sundays than Saturdays (see Figure @fig-iphone).

[^3]: See e.g. [Apples Privacy Policy](https://www.apple.com/legal/privacy/en-ww/).

```{r fig-iphone, fig.align='center', fig.height=8, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Step count data from my iPhone displayed as all avalable data points (A, after data cleaning) and average step per weekday, per year and season (B)."}


library(tidyverse)
library(lubridate)
library(cowplot)


steps <- read_csv2("./data/steps.csv") %>%
  
  mutate(start = dmy_hm(Start), 
         finish = dmy_hm(Finish)) %>%
  

  dplyr::select(start, finish, steps = `Steps (count)`) %>%

  mutate(
    date = format(start, '%Y-%m-%d'),
    month = format(start, '%m'),
    span = (as.numeric(finish - start)/60)/60,
         
         year = format(start, '%Y'), 
         day_of_week = weekdays(start), 
         season = if_else(month %in% c("01", "02", "12"), "Winter", 
                          if_else(month %in% c("03", "04", "05"), "Spring", 
                          if_else(month %in% c("06", "07", "08"), "Summer", 
                          "Autumn")))) %>%
  
  # Remove records that span more than 9 hours
  filter(span < 9) 


steps_fig1 <- steps %>%
  mutate(date = ymd(date)) %>%
  filter(steps < 10000) %>%
  
  ggplot(aes(date, steps)) + geom_point(shape = 21, fill = "blue", alpha = 0.4) + 
  scale_y_continuous(limits = c(0, 2000)) +
  labs(y = "Step (counts)", 
       x = "Date") + 
  theme_minimal()



steps_fig2 <- steps %>%
  group_by(year, day_of_week, season, date) %>%
  summarise(steps = sum(steps)) %>%
  
  group_by(year, day_of_week, season) %>%
  summarise(steps = mean(steps)) %>%
  
  
  mutate(day_of_week = if_else(day_of_week == "mandag", "Monday", 
                               if_else(day_of_week == "tirsdag", "Tuesday",
                                       if_else(day_of_week == "onsdag", "Wednesday",
                                               if_else(day_of_week == "torsdag", "Thursday",
                                                       if_else(day_of_week == "fredag", "Friday",
                                                               if_else(day_of_week == "lørdag", "Saturday","Sunday")))))),
         day_of_week = factor(day_of_week, levels = c("Monday",
                                         "Tuesday", 
                                         "Wednesday",
                                         "Thursday",
                                         "Friday",
                                         "Saturday",
                                         "Sunday")), 
         season = factor(season, levels = c("Winter", "Spring", "Summer", "Autumn"))) %>%
  
  filter(year != "2016") %>%

  ggplot(aes(day_of_week, steps, group = year)) + geom_line() + facet_grid(year ~ season) + 
  
  labs(y = "Average steps per day", 
       x = "Day of the week") + 
  scale_x_discrete()+ 
  theme_minimal() +
  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))
  
  
  plot_grid(steps_fig1, 
            steps_fig2, ncol = 1, 
            rel_heights = c(0.5, 1), 
            labels = "AUTO", 
            label_size = 12)


```

Data are also collected and stored in publicly available databases. Such databases are created for the purpose of storing specific types of data, such as soccer[^4] or biathlon results[^5], or biological information, such as gene sequences[^6]. Even data from scientific studies are often publicly available[^7], meaning we can perform scientific studies on unique data sets without collecting the data ourselves. 

[^4]: [understat.com](https://understat.com/) stores match specific data from major leagues. Data are available through software packages such as [`worldfootballR`](https://jaseziv.github.io/worldfootballR/index.html)

[^5]: [biathlonresults.com/](https://biathlonresults.com/) hosts results from the international biathlon federation. An example of analyzed data can be [seen here](https://sciathlon.github.io/post/biathlon_data_analysis/).

[^6]: [Ensembl](https://www.ensembl.org/) and the [National center for biotechnology information](https://www.ncbi.nlm.nih.gov/) are commonly used databases in the biomedical sciences.

[^7]: We published our raw data together with a recent paper (Mølmen et al 2021 [doi: 10.1186/s12967-021-02969-1.](https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-021-02969-1)) together with code to analyze it in a [public repository](https://github.com/dhammarstrom/rnaseq-copd).

The above examples show an abundance of available data. The problem is that to understand a phenomenon better, we need techniques and methods to make sense of the data, and this is where data science and data literacy comes in. In the world of sports and exercise, regardless if you are interested in doing scientific investigations, coaching a soccer team or individual athletes, or helping patients recover from surgery using exercise therapy, you are faced with the problem of handling and making sense of data. Essential skills and a deeper understanding of data science are transferable between such areas of practice. One broader aim of this course is for you to develop skills to better understand data. 

> **Think about the literature!**
  Spiegelhalter (The Art of Statistics, in the introduction chapter) talks about how statistics has evolved towards the broader field of data science. In data science, statistical theory and methods are just parts of the problem solving cycle. Try to think about how you would use the PPDAC cycle as a exercise coach and a scientist. What are the similarities and differences?



## Replication and Reproducibility

In scientific research, replication is a way to confirm scientific claims. When an independent group of researchers can confirm a result, the claim is more likely to be true. However, many results will be impossible to replicate due to the size of trials, costs, and urgency of the research question. A recent example is the many vaccine trials performed to develop a vaccine against COVID-19[^8]. Other examples concern studies with unique study populations, such as large-scale epidemiological studies [@RN1492], but the same is true for unique investigations in sport and exercise science.  

[^8]: https://www.evaluate.com/vantage/articles/news/snippets/its-official-covid-19-vaccine-trials-rank-among-largest

When studies are not likely to be *replicated*, *reproducibility* of the analyses and results has been suggested to be a minimum standard for scientific studies. Reproducibility means that independent researchers can draw similar results or conclusions from the same data [@RN1492].

Peng et al. [@RN1492] suggests that a *fully reproducible* study has 

- Available data.
- Computer code (software) that produces the results of the study.
- Documentation that describes the software and data used in the study, and
- ways to share the data and code.

The above principally relates to the trust we can place in scientific results. However, the minimum reproducibility standard also has advantages for the individual researcher (or master's student)! When working with reproducible methods, we will develop ways of documenting and automating our analyses. This way of working with analyses will make it easier to collaborate with others. And, as it turns out, your most frequent collaborator is you in the future!

Reproducible data analysis means that you will make it explicit and transparent. In traditional data analysis, most activities are in the "black box." To avoid bias [@RN1953], the "black box" needs to be opened, and you need to actively make transparent decisions all along the analytic pipeline [@RN1955]. This pipeline preferably involves the whole problem-solving cycle described by Spiegelhalter [@RN2902]. However, the tools we will learn in this course focus primarily on the steps from the experimental design to the presentation of statistical results [@RN1955]. These steps include data collection (and storage), data cleaning, exploratory data analysis, statistical modeling, and statistical inference (and communication) [@RN1955].

## Tools in data science

Ways to interpret and make sense of data involve different methods. These methods are often implemented in computer software, which means that when you want to understand data as a practitioner (scientist, coach, analyst), you must master some computer software. Microsoft's Excel is one of the most common software used to understand data, even among professional data scientists[^9]. You can do fantastic stuff with Excel! In the world of sport and exercise, Excel has been used in diverse activities such as scientific investigations, planning and recording training for world champions[^10], and scheduling appointments.


[^9]: (See for example this ranking)[https://www.kdnuggets.com/2019/05/poll-top-data-science-machine-learning-platforms.html]. 

[^10]: The amount of time used by different coaches to create their own specific coaching software really makes many of them amateur software engineers. See for example this training journal from [swedish orienteering](http://obasen.orientering.se/traningsdagbok/installationshandledning.htm).

For scientific research, most people use additional software to do statistical analyses. If you have spent time in higher education, you have probably heard about SPSS, Stata, or Jamovi. These are all specialized software used for statistical analyses.

The tools mentioned above can all be used as part of a fully reproducible workflow. However, some software solutions suit this requirement better than others. Going back to the description of reproducible science as made by Peng et al. [@RN1492], we want software where analyses can be 

- Human- and computer-readable, meaning that we want to be able to write scripts or computer programs that execute the analyses.
- Documented, meaning that along the code, we want to be able to describe what the code does.
- Available and able to share with others, meaning that our analyses can be run on open and free software to maximize the ability to share them.

This means that the software we would prefer should be run using scripts (as opposed to point and click) and be free of charge (and open source, as opposed to expensive and proprietary). These criteria can be fulfilled when we use software written around the R language (although alternatives exist [^11]).

R is a computer language especially well suited for reproducible data analysis. As users can contribute software extensions, also called packages, many specialized software implementations exist for tasks such as creating figures or analyzing specific data. Around R, people have been developing auxiliary software for reproducible data analysis. The negative part of all these opportunities is that using R requires effort. The learning curve is steep!

Even though you might not use R ever again after this course, trying to learn it will let you know something about programming, modern data science capabilities, statistical analysis, and software/computers in general. These areas are all aspects of our modern society and are transferable regardless of what computer language we are talking about.

A big challenge when working with complex analyses or other large projects over time is keeping track of changes. Another challenge might be effective collaboration with others and with yourself in the future. To overcome these challenges, we can use a version control system connected to a social platform for distributing computer code and data. Github is a web-based platform that provides this functionality. It is a potent combination if you want to collaborate and share what you are working on.


[^11]: In addition to R, Python offers a free open source environment for reproducible analyses. The choice between the two are [matter of taste](https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis).

## Installing and getting to know the required software

As noted above, there are multiple computer languages and software solutions that could satisfy our needs. However, in this course, we will focus on a combination of continuously improved tools to make it easy for the user to collaborate and communicate data analyses. Below is a checklist of what you must install on your system to take full advantage of the proposed tools.

### R and RStudio

**R** is a free, [open-source](https://en.wikipedia.org/wiki/Open_source) software designed for statistical computing. We will use R as a part of an environment (using R Studio, introduced below). To download and install R:

1.  Go to <https://cran.uib.no/>,

2.  Select your operating system (Download R for Windows, MacOS or Linux).

    -   If you have Windows, choose `base`, click on "Download R (...) for windows", save and run the file. The installation process should be self explanatory.
    -   If you have MacOS, download and install the latest release.
    
3. Run the installer to install R.



**[RStudio](https://www.posit.co/)** is a software designed to make it easier to use R. It is free to download and use. It is designed as an **integrated development environment** that lets you organize your work together with R and other tools. Install it by going to <https://www.posit.co/>.

1.  Select "Products" and **RStudio IDE**
2.  Scroll down and find the [FREE open source edition](https://posit.co/downloads/)
3.  Download the installer made for your operating system.


### Git and Github

Git is a software that you need to install on your system in order to use version control. Github is the web platform that allows collaboration and web-based storage of your work. First, we will install git.

For windows:

1. If you have Windows, Go to [https://git-scm.com/downloads](https://git-scm.com/downloads) and download the latest version for your operating system.

2. Run the installer. Make a note of where you installed it!


For Mac:

1. If you are on Mac, the easiest thing is to first install [*Homebrew*](https://brew.sh/), this will make it easy to get the latest version of what we will need. Go to [https://brew.sh/](https://brew.sh/) and follow the instructions. Note that you will need to open the terminal and enter the install command.

2. Install git by entering the follwing command in a freshly opened terminal:

`brew install git`

Check if git was installed by restarting the terminal and write

`git --version`

Additional warnings might appear indicating that you'll need some extra software. More specifically, you might need Xcode command line tools. To install these, go to your terminal and enter

`xcode-select --install`

If you had problems with the homebrew installation itself or the brew installation of git before, try again after installing xcode command line tools. 


### Connecting to GitHub


First we will let RStudio know where git is located

1. Open RStudio, go to *Global Options* under the *Tools* menu. Go to the *Git/SVN* sub-menu and find the **folder where git.exe** is located by browsing in the *"Git executable"* field.

**On windows:**

If you have installed git using default settings your `git.exe` should be located in `C:/Program Files/Git/bin/git.exe`.

**On Mac**:

If you have installed git using homebrew, your git version *may* be found in `/usr/local/bin/git`.


To register for a Github account

1. Go to [Github.com](www.github.com).
2. Find "Sign up" and follow the instructions.


Next we need to connect our git software to github. This is done by *authentication*. [There are several options](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/about-authentication-to-github), however below are two options that should work right away!

#### Installing GitHub desktop

1. Go to [desktop.github.com](https://desktop.github.com/)
2. Download the installer and follow the instructions.
3. Open GitHub Desktop and go to File > Options > Accounts and select **Sign In** to Github.com, follow the instructions


#### Installing Github CLI

If you were successful in authenticating with Github desktop as described above, you should be all set. However, as an alternative you could install and use Github CLI. This is a collection of command line commands that makes it easy to use github from the command line. I recommend installing them:

1. Go to [https://cli.github.com/](https://cli.github.com/) and follow the instructions.

  - For windows, install GitHub CLI with the installer. 
  - For Mac, use homebrew: `brew install gh`


Next we will perform the authentication process:

1. Open a terminal and type `gh auth login`, follow the instructions. 

Done!


### A note on Git and clients

As noted above, git is a software containing a number of functions for version control of files collected in a folder (or repository). A client in this context refers to a *user interface* that makes it easy to communicate with git. RStudio has some features that makes it possible to execute git commands by clicking, however this *client* is not very powerful, you might want another, or several other alternatives.

First, git is available from the command line. It might look like this:


`git add -A`


We will touch upon more git commands for the command line later. The above adds all changes you have made to a list of changes that will be included in your next snapshot of your project. More on that later!

Several Git clients can be run at the same time. This means that you might do some git on the command line in a terminal window in RStudio, and you might follow the changes in a graphical user interface, such as [GitHub Desktop](https://desktop.github.com/). The graphical user interface lets you navigate more easily and might help you understand what git is doing. We will be using GitHub desktop, so you make sure you have installed it (see above).


### Quarto and friends

The R community has pioneered literate programming for data analysis by early adoption of file formats that lets the user combine computer code and output with text [@RN1492]. A well adopted file format in recent years have been [R markdown](https://rmarkdown.rstudio.com/) which combines R code with text and lets the user compile reports in multiple output formats from a source document. R markdown is an "R-centric" approach to literate programming. Even though it lets you combine multiple computer languages, all code execution goes through R. Recently, a new format has been introduced, [Quarto](https://quarto.org/), which is not executed through R but its own dedicated software, Quarto. 

Rmarkdown and Quarto have many similarities in that you can use markdown, a well established [markup language](https://en.wikipedia.org/wiki/Markdown) to format text with a plain text editor (like notepad). This means that for the R user, most differences between RMarkdown and quarto in formatting your documents are irrelevant for getting started.

As quarto authoring requires its own software, we need to do some installation.

1. Go to [quarto.org](https://quarto.org/)
2. Click "*Get Started*" and follow the instructions. 

A nice output from a quarto source documents is a PDF. In order to create PDFs using R/RStudio/quarto we need to install a version of the typesetting system [TeX](https://en.wikipedia.org/wiki/TeX). Quarto recommends[^12] using [tinytex](https://yihui.org/tinytex/) which is easily installed after you have installed quarto.

1. Open up RStudio and a fresh terminal
2. type `quarto install tinytex` and follow the instructions. 

You should be ready to go now!

[^12]: See the quarto documentation for details on creating pdfs and installing TeX distributions https://quarto.org/docs/output-formats/pdf-basics.html


## Summing up and where to find help

We have installed R, RStudio, git, GitHub desktop/CLI, quarto and tinytex. You have also created a github account. These are the tools that you will need to go further in this course. But what if you run into problems? Do not worry, the internet is at your service! A lot of people work very hard to make it easy for beginners to adopt their tools. Documentation of the tools we have installed so far is available through google or any other search engine. People are also very helpful in answering questions, answers to large and small problems can be found in forums such as [stack overflow](https://stackoverflow.com/)(see below). 

Learning new skills, like doing data analysis by programming, can be hard but rewarding. If you want to make your learning experience less hard, consider these points:

- **There are (almost always) multiple solutions to a problem**. When faced with difficulties, do not give up trying to search for a perfect single solution. Instead know that there are multiple ways of defining the problem and therefore multiple ways of making stuff work.
- **Someone else has already had the same problem**. The internet is full of questions and answers, also related to what ever problem you might have. Learning how to write "googleable" questions is a great skill. By adding "in R" to your problem in a google search term often helps finding R related solutions.
- **Find your motivation**. The skills that you will learn in this course are transferable to countless potential work related roles for the future you! To be able to showcase these skills may lead you to your dream job! Find your motivation for learning how to analyze data and communicating insights!
- **"Microdosing" statistical learning**. Replace your social media influencers with R users and data scientists! I find R people on [Twitter](twitter.com) and [mastodon](https://joinmastodon.org/). Tweets and posts in this format keeps your R brain going!

### A (small) list of reference material and resources


- [R for Data Science](https://r4ds.hadley.nz/) is a very comprehensive guide to working with R. It can be used chapter by chapter or by looking for tips on specific subjects.

- The official [An Introduction to R](https://cran.r-project.org/doc/manuals/R-intro.pdf) released by the R Core Team gives a thorough overview of R. This document can be used to find explanations to basic R code.

- [Learning statistics with R](https://learningstatisticswithr.com/) Is a free textbook where statistical concepts are integrated with learning R. Use this book as a reference.

- [Happy Git and GitHub for the useR](https://happygitwithr.com/index.html) is used as background material for our workshop in version control and collaborative data analysis.

- [Tidyverse](https://www.tidyverse.org/) Is a collection of R packages that makes it easier to be productive in R. Here you will find documentation for ggplot, dplyr and tidyr which are all packages that we will use extensively in the course.

- [Stack overflow](https://stackoverflow.com/) is a web platform where users provide answers to questions raised by other users. Here you will find answers to many of your R-related questions. Stack overflow will likely come up if you google a R problem by you can also search the website.

- [R bloggers](https://www.r-bloggers.com/) collects blog posts from R users, here you can find interesting use cases of R and tips.




## References and footnotes

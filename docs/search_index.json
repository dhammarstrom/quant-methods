[["index.html", "Quantitative methods and statistics (In Sport and Exercise Science) Chapter 1 Introduction 1.1 Practical information 1.2 Assignments and Portfolio exam 1.3 Other information", " Quantitative methods and statistics (In Sport and Exercise Science) Daniel Hammarström Updated: 2021-08-10 Chapter 1 Introduction Welcome to the course Quantitative methods and Statistics (IDR4000). The course aims to give students an overview of methodological aspects within the field of sport and exercise-physiology. Specifically, planning, conducting and analyzing research projects with human participants will be covered. These course notes covers almost the entire course through the combination of video lectures, tutorials and references to the course literature and external resources. INTRO VIDEO LECTURE 1.1 Practical information 1.1.1 Learning objectives Learning objectives can be read in Norwegian here. 1.1.2 Learning strategies The course will include lectures, laboratory exercises, computer exercises, seminars and student presentations. Lectures will be held on-line (zoom), as pre-recorded in this book and in-person on campus. Due to the current pandemic, you are required to do laboratory exercises in your cohort. Computer exercises require that you have special computer software installed on your computer. The software is free (see specific chapters in these course notes). Assignments will be presented in this text with information on how to hand them in. The whole course is evaluated based on a portfolio (see below). 1.1.3 Course evaluation As a student you can contribute to the quality of the course by engaging in course evaluation throughout the course. You will be asked to answer a pre-course questionnaire about your expectations and a post-course questionnaire about your experiences. You are also welcomed to take part in systematic discussions during the course about the quality of teaching and course material. With these notes I want to underline the importance of student participation in the continuous development of the course (and program) teaching/learning qualities. 1.1.4 Lecturers and course administration In order of appearance Daniel Hammarström (daniel.hammarstrom@inn.no), is responsible for course administration and will be teaching statistics and molecular methods. Kristian Lian, Ingvill Odden and Lars Nymoen will act as teacher assistants in organizing methods in the physiology lab. Stein Olaf Olsen will act as a teacher assistant in the molecular lab. Prof. Carten Lundby will cover aspects CO2 re-breathing techniques (physiology). Prof. Finnur Dellsén will cover philosophy of science. Prof. Stian Ellefsen will teach molecular methods. 1.1.5 Updates, notifications and general communication These course notes will be updated during the course. General information and last minute changes will be posted on Canvas, make sure to check it as part of your daily study routine. 1.1.6 Literature A full list of recommended literature can be found here. Literature will be referenced in specific sections in these course notes. 1.1.7 Grades The course is graded pass/fail. 1.1.8 Language My (Daniel) first language is Swedish, Im sure most of you will understand what Im talking about. However, due to the fact that we accept international students to the program, most written communication and some lectures will be in English. You are not expected to write in English, it is however possible! 1.2 Assignments and Portfolio exam The course is based on several assignments. Some of these assignments are to be handed in as part of a portfolio exam upon which your grade is based. Assignments that are due during the course (arbeidskrav) are expected to be further improved after feedback from fellow students and teachers before inclusion in your portfolio. The table below shows all assignments that are part of the course. Some are not to be included in the portfolio and some assignments are group assignments (see Table). Assignment Due date Included in portfolio Group assignment Descriptive statistics, reliability and validity 2021-09-10 Yes Yes Study designs 2021-10-01 Yes No Extraction and analysis of DNA 2021-10-15 Optionala Yes Extraction of RNA and analysis of qPCR experiments 2021-10- Optionala Yes Extraction and analysis of Protein 2021-10- Optionala Yes Regression models and prediction from data 2021-10- No Yes Drawing inference from statistical models 2021-10- No Yes Statistical power and sample size calculations 2021-11- Yes Yes Analyzing repeated measures experiments 2021-11- Yes No Philosophy of scienceb 2021-11- Yes No a Select one laboratory assignments for your portfolio exam. b This assignment is presented in connection with lectures. In addition to arbeidskrav/assignments, smaller assignments and quizzes are presented in this book, but you are not required to do them to pass the course. 1.3 Other information "],["introduction-to-data-science.html", "Chapter 2 Introduction to data science 2.1 About data in the world of sport and exercise 2.2 Replication and Reproducibility 2.3 Tools in data science", " Chapter 2 Introduction to data science 2.1 About data in the world of sport and exercise Data is everywhere. Most of us walk around with a data collection device in our pockets all the time. This device (your mobile phone), records and store data about you all throughout the day. Such data are the basis of the quantified self movement1 that have grown in popularity as capabilities to record data from daily life has become better. People interested in quantifying their personal life does so for different reasons, but often with the intent to improve their health2. Much of these kind of data are readily available to us due to the fact we are protected by data privacy policies and regarded as personal data3. With some effort you yourself can get your data out of your iphone to explore, for example, your daily step count. I discovered that my phone(s) has been collecting data for me since 2016 and I tend to walk less steps on Sundays compared to Saturdays (see Figure 2.1). Figure 2.1: Step count data from my iPhone displayed as all avalable data points (A, after data cleaning) and average step per weekday, per year and season (B). Data are also collected and stored in publicly available databases. Such databases are created for the purpose to store specific types of data, such as soccer4 or biathlon results5, or biological information such as gene sequences6. Even data from scientific studies are now days often publicly available7 meaning that we can perform scientific studies on unique data sets without collecting the data ourselves. The above examples shows that there are abundance of data around and available to us. The problem is that it is hard understand all this data. This is where data science and data literacy comes in. In the world of sport and exercise, regardless if you are interested in doing scientific investigations, coach a soccer-team or individual athletes or help patients recover from surgery using exercise therapy, you are faced with the problem of handling and make sense of data. Some of the key skills and deeper understanding about data science are very much transferable between such areas of practice. Think about the literature! Spiegelhalter (The Art of Statistics, in the introduction chapter) talks about how statistics has evolved towards the broader field of data science. In data science, statistical theory and methods are just parts of the problem solving cycle. Try to think about how you would use the PPDAC cycle as a exercise coach and a scientist. What are the similarities and differences? One broader aim of this course is for you to develop skills to better understand data. 2.2 Replication and Reproducibility In scientific research, replication is a way to confirm scientific claims. When a result can be confirmed by an independent group of researchers, the claim is likely more true. Many results will however never be possible to replicate due to the size of trials, costs and urgency of the research question. A recent example could perhaps be the many vaccine trials performed to develop a vaccines against COVID-198. Other examples concern studies with unique study populations, such as large scale epidemiological studies (Peng, Dominici, and Zeger 2006), but the same could be said to be true for unique investigations in sport and exercise science. When studies are not likely to be replicated, reproducibility of the analyses and results has been suggested to be a minimum standard for scientific studies. Reproducibility means that given the same datas, similar results or conclusions can be drawn by independent researchers (Peng, Dominici, and Zeger 2006). Peng et al. (Peng, Dominici, and Zeger 2006) suggests that a fully reproducible study has Available data. Computer code (software) that produces the results of the study. Documentation that describes the software and data used in the study, and ways to share the data and code. The above principally relates to the trust we can place in scientific results. However, the minimum standard of reproducibility has advantages also for the individual researcher (or master student)! When working with reproducible methods we will develop ways of documenting and automating our analyses. This will make it easier to collaborate with others. And, as it turns out, your most frequent collaborator is you, in the future! A reproducible data analysis means that you will make it explicit and transparent. In a traditional data analysis, most activities are in the black box. In order to avoid bias (Ioannidis 2005), the black box needs to be opened and you need to actively make transparent decisions all along the analytic pipeline (Leek and Peng 2015). This pipeline preferably involves the whole problem solving cycle described by Spiegelhalter (Spiegelhalter 2019). However the tools that we will learn about in this course focuses primarily on the steps from the experimental design to presentation of statistical results (Leek and Peng 2015). These steps includes data collection (and storage), data cleaning, exploratory data analysis, statistical modelling and statistical inference (and communication) (Leek and Peng 2015). 2.3 Tools in data science Ways to interpret and make sense of data involves different methods. These methods are now days often implemented in computer software. This means that when you as a practitioner (scientist, coach, analyst ) want to understand data, you have to master some kind of computer software. The most common software used to understand data is probably Microsofts Excel. You can do amazing stuff with Excel! In the world of sport and exercise Excel has been used in such diverse activities such as scientific investigations, planning and recording training for Olympic medalists9 and scheduling appointments. For scientific research, most people use additional software to do statistical analyses. If you have spent time in higher education you have probably heard about SPSS, Stata or Jamovi. These are all specialized software used for statistical analyses. The above mentioned tools can all be used as part of a fully reproducible workflow. However, there are software solutions that actually suits this requirement better than others. Going back to the description of reproducible science as made by Peng et al. (Peng, Dominici, and Zeger 2006), we want software where analyses can be Human- and computer-readable, meaning that we want to be able to write scripts, or computer programs that execute the analyses. Documented, meaning that along the code we want to be able to describe what the code does. Available and able to share with other, meaning that we analyses can be run on open and free software to maximize ability to share them. This means that the software that we would prefer should be run using scripts (as opposed to point and click) and be free of charge (and open source, as opposed to expensive and proprietary). These criteria can be fulfilled when we use software that is written around the R language (although alternatives exists10). R is a computer language that is especially well suited for reproducible data analysis. As users are able to contribute software extensions, also called packages, many specialized software implementation exists for different tasks, such as creating figures or analyses of specific data. Around R, people have been developing auxiliary software to enable reproducible data analysis. The negative part of all these opportunities is that using R requires some effort. The learning curve is steep! Even though you might not use R ever again after this course, making and effort trying to learn it will let you know something about programming, capabilities of modern data science, statistical analysis and software/computers in general. These areas are all part of our modern society and are very much transferrable regardless of what computer language we are talking about. In a following chapter of these course notes we will go through installing and starting up R. References "],["storing-data-in-spreadsheets.html", "Chapter 3 Storing data in spreadsheets 3.1 Cells and simple functions 3.2 Tidy data and data storage 3.3 Recording data 3.4 Saving data", " Chapter 3 Storing data in spreadsheets I previously mentioned spreadsheets like those created in Excel. These are indeed great, but not great for reproducible science or data analysis. This is because they are not easily documented and scripted. The data is actually part of the analysis. Another danger with spreadsheets (like MS Excel) is that it re-formats your data. This is such a big problem for scientists that we have apparently started renaming genes. Errors are frequent in spreadsheets, not only because renaming (Ziemann, Eren, and El-Osta 2016), but also because of bad formatting of formulas (Stephen, Kenneth, and Barry 2009). These are both reasons for using spreadsheets only for what they do best: data input and data storage. Think about the literature Broman and Woo (Broman and Woo 2018) gives several pointers on how to use spreadsheets for data input and storage. Think about your experince with Excel, what is the most common mistake you made when handling data in spreadsheets? Although data storage and data input are great ways to use spreadsheets, its good to know a little about the capabilities of your spreadsheet software. 3.1 Cells and simple functions A spreadsheet consists of cells, these can contain values, such as text, numbers, formulas and functions. Cells may also be formatted with attributes such as color or text styles. Below is an example of some data entered in a spreadsheet. Figure 3.1: Example entries from an Excel spreadsheet Cell B6 contains a simple formula: = C6 + D6. This formula adds cells C6 and D6 resulting in the sum, 8. In formulas, mathematical operators can be used (\\(+, -, \\times , \\div\\) ). Formulas can be also extended with inbuilt function such as showed in 3.1. Table 3.1: Often used functions in excel. Function English Norwegian Sum SUM() SUMMER() Average AVERAGE() GJENNOMSNITT() Standard deviation STDEV.S() STDEV.S() Count COUNT() ANTALL() Intercept INTERCEPT() SKJÆRINGSPUNKT() Slope SLOPE() STIGNINGSTALL() If IF() HVIS() The sum, average and standard deviation and count are simple functions for summarizing data. Intercept and slope are both examples of functions used to get simple associations from to sets of numbers (based on a regression model). The if function is an example of a function that can be used to conditionally enter data in a cell. For example, IF cell A1 contains a certain number, then cell B1 should display another a specified text. When looking for tips and tricks online, you may come across functions for excel in other languages than what is installed on your computer. To translate functions, and for a full overview of functions included in Microsoft Excel, see this website en.excel-translator.de/. 3.2 Tidy data and data storage Hadley Wickham uses a quote from Tolstoy when describing the principle of tidy data (Wickham 2014). This quote is so famous that it has given name to a principle. The principle in turn comes in many variants but basically states that when something goes wrong, it can be wrong in multiple ways. But when it is right/correct/works/succeeds, it does so in only one way11. This principle can be applied to data sets. There are so many ways that formatting of data sets can be problematic, but a limited sets of principles makes it good. Figure 3.2: Leo Tolstoy at the time when he was (possibly) authoring Anna Karenina. (Source: https://en.wikipedia.org/wiki/Leo_Tolstoy) A tidy data set consists of values originating from observations and belonging to variables. A variable is a definition of the values based on attributes. An observation may consist of several variables (Wickham 2014). A tidy data set typically has got one observation per row and one variable per column. Lets say that we want to collect data from a strength test. A participant (participant is a variable) in our study conducts tests before and after the intervention (time is a variable) in two exercises (exercise is a variable) and we record the maximal strength in kg (load is a variable). The data set will look something like in the table below (3.2). Table 3.2: Example of tidy data. Participant Time Exercise Load Bruce Wayne pre Bench press 95 Bruce Wayne post Bench press 128 Bruce Wayne pre Leg press 180 Bruce Wayne post Leg press 280 Another example contains variables that actually carries two pieces of information in one variable. We again did a strength test, this time as maximal isometric contractions and in each test consisted of two attempts. We record this in two different variables, attempt 1 and 2. The resulting data set could look something like in Table 3.3. Table 3.3: Another example of tidy data. Participant Time Exercise Attempt1 Attempt2 Selina Kyle pre Isometric 81.3 92.5 Selina Kyle post Isometric 97.1 114.1 To make this data set tidy we need to extract the attempt information and record it in another variable as seen in Table 3.4. Table 3.4: A third example of tidy data. Participant Time Exercise Attempt load Selina Kyle pre Isometric 1 81.3 Selina Kyle pre Isometric 2 92.5 Selina Kyle post Isometric 1 97.1 Selina Kyle post Isometric 2 114.1 This naturally gives additional rows to the data set. This is sometimes referred to as long format data as opposed to the structure where each attempt is given separate variables, something that is called wide format. You will notice during the course that for most purposes, the long format is most convenient. This is true when we create graphs and do statistical modelling. But sometimes a variable needs to be structured in a wide format to allow for certain operations. If we follow what is recommended by Broman and Woo (Broman and Woo 2018), it is clear that each cell in a spreadsheet should only contain one value. If we for example decide to format a cell to a certain color, we add data to that cell on top of the actual data. You might add color to a cell in order to remember to add or change data. However, when you use the data set in other software, this information is lost. You should instead add another variable to allow for such data to be properly recorded. Using a variable called comments you can add text thta actually describes some information about that particular observation, information that is not lost when you use the data set in another software. 3.3 Recording data A trade secret12 from people who work all day with data and programming is that they are lazy. Lazy in the sense that you do not want to type too much, and absolutely not use the computer mouse when it can be avoided. When recording data we can try to be lazy to. We can do this by shortening variable names and not e.g. using CAPITAL letters when entering text in data storage. After a hard day at the keyboard, you will be happy to write strtest instead of Strength Test. The extra effort of using two capital letters might be the thing to tip you over the edge13. However, we should not be too lazy either, variable names and values should short, but meaningful (Broman and Woo 2018). Figure 3.3: D-FENS Foster gets pushed over the edge (Source: https://en.wikipedia.org/wiki/Falling_Down) Data and variables should also be consistent. Do not mix data type, use a consistent way of entering e.g. dates and time, do not uses spaces or special characters. To enforce this you might want start your data collection with writing up a data dictionary that describes all variables you are collection. The dictionary can set the rules for your variables. This dictionary can also guide your data validation. In Excel, data validation can be used to set rules for data entry. For example, if you have a numeric variable, you can set Excel only to accept numbers in specified set of cells. This makes it harder to enter erroneous data. 3.4 Saving data Data from spreadsheets can be saved as special spreadsheet files, such as .xlsx. This format allows for functions, multiple spreadsheets in the same file (tabs) and cell formatting. If you follow the tips described above and in (Broman and Woo 2018) you do not need this fancy format. Instead you can store your data as a .csv file. This format may be read and edited with Excel (or another spreadsheet software) but also in a plain text editor. Data entered in this format (comma-separated values; csv) can look like this in a text editor: Participant;Time;Exercise;Attempt;load Selina Kyle;pre;Isometric;1;81.3 Selina Kyle;pre;Isometric;2;92.5 Selina Kyle;post;Isometric;1;97.1 Selina Kyle;post;Isometric;2;114.1 This is actually quite nice. The data takes little space, the simple format requires that data is well documented using e.g. a data dictionary and it is available for many other softwares as the format is simple. The data can be documented using a README file that could describe the purpose and methods of data collection, how the data is structured and what kind of data the variables contains. A simple README file can be written in a text editor such as Notepad and saved as a .txt file. Later in this course we will introduce a markup language often used to create README files containing a syntax that formats the text to a more pleasant style when converted to other formats. References "],["installing-and-starting-up-r-and-r-studio.html", "Chapter 4 Installing and starting up R (and R Studio) 4.1 Installing R 4.2 Installing R Studio 4.3 Getting to know R and RStudio 4.4 Reproducible computing 4.5 Packages 4.6 Installing and using swirl", " Chapter 4 Installing and starting up R (and R Studio) This chapter contains step-by-step instructions for installing and running R and R Studio. It will also introduce you to some concepts when talking to R. By the end of this chapter you will be able to answer these questions: What is R and RStudio? How can I interact with R? What are the components of RStudio How do I maintain a reproducible work-flow in R and RStudio? 4.1 Installing R R is a free, open-source software designed for statistical computing. We will use R as a part of a environment (using R Studio, introduced below). To download and install R: Go to https://cran.uib.no/, select your operating system (Download R for Windows, MacOS or Linux). If you have Windows, choose base, click on Download R () for windows, save and run the file. The installation process should be self explanatory. If you have MacOS, download and install the latest release. 4.2 Installing R Studio RStudio is a software designed to make it easier to use R. It is free to download and use. It is designed as an integrated development environment that lets you organize your work together with R and other tools. Install it by going to https://www.rstudio.com/. Select Products and RStudio Go to desktop and select DOWNLOAD RSTUDIO DESKTOP Select the free open source license and download the file made for your operating system (use the installers). 4.3 Getting to know R and RStudio R is a software used for scientific/statistical computing. If R is the engine, RStudio is the rest of the car. What does this mean? When doing operations in R, you are actually interacting with R through RStudio. RStudio have some important components to help you interact with R. 4.3.1 The source The source is where you keep your code. When writing your code in a text-file, you can call it a script, this is essentially a computer program where you tell R what to do. It is executed from top to bottom. You can send one line of code, multiple lines or whole sections into R. In the image below, the source window is in the top left corner. 4.3.2 Environment The environment is where all your objects are located. Objects can be variables or data sets that you are working with. In RStudio the environment is listed under the environment tab (bottom left in the image). Copy and run the code below. a &lt;- c(1, 2, 4) What happened in your environment? 4.3.3 The console Here you can directly interact with R. This is also where output from R is printed. In the image below, the console is in the top right corner. 4.3.4 Files, plots, packages and help files In RStudio files are accessible from the Files tab. When opening a project, the files tab shows the files in you root folder. Plots are displayed in the Plot tab. Packages are listed in the packages tab. If you access the help files, these will be displayed in the help tab. In the image below all these tabs are in the bottom right corner. Figure 4.1: RStudio when first opened up. 4.3.5 Customizing the apperance of RStudio To access options for RStudio, go to Tools -&gt; Global options Figure 4.2: Accessing options for your RStudio IDE Under appearance you can customize the theme of RStudio, select something that is easy on the eye! Figure 4.3: Accessing options for your RStudio IDE and selection a theme Under pane layout, you can set where you want your tabs, I like to have the source on the left, above the environment. This way you can have the source window at full vertical size and still look at plots and the console to the right. Figure 4.4: Accessing options for your RStudio IDE and set the panes 4.4 Reproducible computing Computations are reproducible when you can show how they were performed. This is achieved by creating programs from where your analyses are done. In R, these programs are lines or R code stored in a text-file, either .R-files or .Rmd-files. .R-files are scripts only containing code and comments. A .Rmd-file is a special script combining text and computer code, when the Rmd-file is executed, it creates a report and outputs the results from the code. This means that to work in a reproducible way, you need to script all your operations. Figure 4.5: Reproducible vs. non-reproducible workflow Importantly, in RStudio you can shut down storing temporary objects in a environment that is relaunched on start up. What is the consequence of having such a situation? To disable this option, set save works pace to NEVER! Figure 4.6: Set the workspace option to never save. 4.5 Packages The R ecosystem consists of packages. These are functions organized in a systematic manner. Functions are created to perform a specialized task. And packages often have many function used to do e.g. analyses of a specific kind of data, or more generl task such as making figures or handle data. In this course we will use many different packages, for example dplyr, tidyr and ggplot2. dplyr and tidyr are packages used to transform and clean data. ggplot2 is used for making figures. To install a package, you use the install.packages() function. You only need to do this once on your computer (unless you re-install R). You can write the following code in your console to install dplyr. install.packages(&quot;dplyr&quot;) Alternatively, click Packages and Install and search for the package you want to install. To use a package, you have to load it into your environment. Use the library() function to load a package. library(&quot;dplyr&quot;) 4.6 Installing and using swirl Swirl is a great way to get to know how to talk with R. Swirl consists of lessons created for different topics. Install swirl by typing the following into your console: install.packages(&quot;swirl&quot;) Or select swirl in the Package/Install menu. "],["creating-your-first-graph.html", "Chapter 5 Creating your first graph", " Chapter 5 Creating your first graph R is an excellent environtment for scientific graphs. There are three main systems for graphical output from R. The first is included in base R. "],["creating-your-first-table.html", "Chapter 6 Creating your first table", " Chapter 6 Creating your first table "],["writing-your-first-reproducible-report.html", "Chapter 7 Writing your first reproducible report", " Chapter 7 Writing your first reproducible report "],["references.html", "Chapter 8 References", " Chapter 8 References "]]

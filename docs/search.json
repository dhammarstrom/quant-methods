[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science)",
    "section": "",
    "text": "1 Introduction\nWelcome to the course Quantitative methods and Statistics (IDR4000). The course aims to give students an overview of methodological aspects within the field of sport and exercise-physiology. Specifically, planning, conducting and analyzing research projects with human participants will be covered. These course notes covers almost the entire course through the combination of video lectures, tutorials and references to the course literature and external resources.\nThis book contains lecture notes for the course. Assignments, tutorials and other cours material has been moved to the course workshop site"
  },
  {
    "objectID": "01-intro-to-data.html#about-data-in-the-world-of-sport-and-exercise",
    "href": "01-intro-to-data.html#about-data-in-the-world-of-sport-and-exercise",
    "title": "2  Introduction to data science",
    "section": "2.1 About data in the world of sport and exercise",
    "text": "2.1 About data in the world of sport and exercise\nData are everywhere. Most of us walk around with a data collection device in our pockets all the time. This device (your mobile phone), records and store data about you all throughout the day. Such data are the basis of the quantified self movement1 that have grown in popularity as capabilities to record data from daily life has become better. People interested in quantifying their personal life does so for different reasons, but often with the intent to improve their health2.\nMuch of these kind of data are readily available to us due to the fact we are protected by data privacy policies and regarded as personal data3. With some effort you yourself can get your data out of your iphone to explore, for example, your daily step count. I discovered that my phone(s) has been collecting data for me since 2016 and I tend to walk less steps on Sundays compared to Saturdays (see Figure @ref(fig:iphone-data)).\n\n\n\n\n\nStep count data from my iPhone displayed as all avalable data points (A, after data cleaning) and average step per weekday, per year and season (B).\n\n\n\n\nData are also collected and stored in publicly available databases. Such databases are created for the purpose to store specific types of data, such as soccer4 or biathlon results5, or biological information such as gene sequences6. Even data from scientific studies are now days often publicly available7 meaning that we can perform scientific studies on unique data sets without collecting the data ourselves.\nThe above examples shows that there are abundance of data around and available to us. The problem is that it is hard understand all this data. This is where data science and data literacy comes in. In the world of sport and exercise, regardless if you are interested in doing scientific investigations, coach a soccer-team or individual athletes or help patients recover from surgery using exercise therapy, you are faced with the problem of handling and make sense of data. Some of the key skills and deeper understanding about data science are very much transferable between such areas of practice.\n\nThink about the literature! Spiegelhalter (The Art of Statistics, in the introduction chapter) talks about how statistics has evolved towards the broader field of data science. In data science, statistical theory and methods are just parts of the problem solving cycle. Try to think about how you would use the PPDAC cycle as a exercise coach and a scientist. What are the similarities and differences?\n\nOne broader aim of this course is for you to develop skills to better understand data."
  },
  {
    "objectID": "01-intro-to-data.html#replication-and-reproducibility",
    "href": "01-intro-to-data.html#replication-and-reproducibility",
    "title": "2  Introduction to data science",
    "section": "2.2 Replication and Reproducibility",
    "text": "2.2 Replication and Reproducibility\nIn scientific research, replication is a way to confirm scientific claims. When a result can be confirmed by an independent group of researchers, the claim is more likely to be true. Many results will however never be possible to replicate due to the size of trials, costs and urgency of the research question. A recent example could perhaps be the many vaccine trials performed to develop a vaccines against COVID-198. Other examples concern studies with unique study populations, such as large scale epidemiological studies (Peng, Dominici, and Zeger 2006), but the same could be said to be true for unique investigations in sport and exercise science.\nWhen studies are not likely to be replicated, reproducibility of the analyses and results has been suggested to be a minimum standard for scientific studies. Reproducibility means that given the same datas, similar results or conclusions can be drawn by independent researchers (Peng, Dominici, and Zeger 2006).\nPeng et al. (Peng, Dominici, and Zeger 2006) suggests that a fully reproducible study has\n\nAvailable data.\nComputer code (software) that produces the results of the study.\nDocumentation that describes the software and data used in the study, and\nways to share the data and code.\n\nThe above principally relates to the trust we can place in scientific results. However, the minimum standard of reproducibility has advantages also for the individual researcher (or master student)! When working with reproducible methods we will develop ways of documenting and automating our analyses. This will make it easier to collaborate with others. And, as it turns out, your most frequent collaborator is you, in the future!\nA reproducible data analysis means that you will make it explicit and transparent. In a traditional data analysis, most activities are in the “black box”. In order to avoid bias (Ioannidis 2005), the “black box” needs to be opened and you need to actively make transparent decisions all along the analytic pipeline (Leek and Peng 2015). This pipeline preferably involves the whole problem solving cycle described by Spiegelhalter (Spiegelhalter 2019). However the tools that we will learn about in this course focuses primarily on the steps from the experimental design to presentation of statistical results (Leek and Peng 2015). These steps includes data collection (and storage), data cleaning, exploratory data analysis, statistical modelling and statistical inference (and communication) (Leek and Peng 2015)."
  },
  {
    "objectID": "01-intro-to-data.html#tools-in-data-science",
    "href": "01-intro-to-data.html#tools-in-data-science",
    "title": "2  Introduction to data science",
    "section": "2.3 Tools in data science",
    "text": "2.3 Tools in data science\nWays to interpret and make sense of data involves different methods. These methods are now days often implemented in computer software. This means that when you as a practitioner (scientist, coach, analyst …) want to understand data, you have to master some kind of computer software. The most common software used to understand data is probably Microsoft’s Excel. You can do amazing stuff with Excel! In the world of sport and exercise Excel has been used in such diverse activities such as scientific investigations, planning and recording training for Olympic medalists9 and scheduling appointments.\nFor scientific research, most people use additional software to do statistical analyses. If you have spent time in higher education you have probably heard about SPSS, Stata or Jamovi. These are all specialized software used for statistical analyses.\nThe above mentioned tools can all be used as part of a fully reproducible workflow. However, there are software solutions that actually suits this requirement better than others. Going back to the description of reproducible science as made by Peng et al. (Peng, Dominici, and Zeger 2006), we want software where analyses can be\n\nHuman- and computer-readable, meaning that we want to be able to write scripts, or computer programs that execute the analyses.\nDocumented, meaning that along the code we want to be able to describe what the code does.\nAvailable and able to share with other, meaning that we analyses can be run on open and free software to maximize ability to share them.\n\nThis means that the software that we would prefer should be run using scripts (as opposed to point and click) and be free of charge (and open source, as opposed to expensive and proprietary). These criteria can be fulfilled when we use software that is written around the R language (although alternatives exists10).\nR is a computer language that is especially well suited for reproducible data analysis. As users are able to contribute software extensions, also called packages, many specialized software implementation exists for different tasks, such as creating figures or analyses of specific data. Around R, people have been developing auxiliary software to enable reproducible data analysis. The negative part of all these opportunities is that using R requires some effort. The learning curve is steep!\nEven though you might not use R ever again after this course, making and effort trying to learn it will let you know something about programming, capabilities of modern data science, statistical analysis and software/computers in general. These areas are all part of our modern society and are very much transferable regardless of what computer language we are talking about.\nIn a following chapter of these course notes we will go through installing and starting up R."
  },
  {
    "objectID": "01-intro-to-data.html#footnotes",
    "href": "01-intro-to-data.html#footnotes",
    "title": "2  Introduction to data science",
    "section": "",
    "text": "Read more about the quantified self movement in this Wikipedia article↩︎\nSee this website for intriguing examples↩︎\nSee e.g. Apples Privacy Policy.↩︎\nunderstat.com stores match specific data from major leagues. Data are available through software packages such as worldfootballR↩︎\nbiathlonresults.com/ hosts results from the international biathlon federation. An example of analyzed data can be seen here.↩︎\nEnsembl and the National center for biotechnology information are commonly used databases in the biomedical sciences.↩︎\nWe published our raw data together with a recent paper (Mølmen et al 2021 doi: 10.1186/s12967-021-02969-1.) together with code to analyze it in a public repository.↩︎\nhttps://www.evaluate.com/vantage/articles/news/snippets/its-official-covid-19-vaccine-trials-rank-among-largest↩︎\nThe amount of time used by different coaches to create their own specific coaching software really makes many of them amateur software engineers. See for example this training journal from swedish orienteering.↩︎\nIn addition to R, Python offers a free open source environment for reproducible analyses. The choice between the two are matter of taste.↩︎"
  },
  {
    "objectID": "01-intro-to-data.html#references",
    "href": "01-intro-to-data.html#references",
    "title": "2  Introduction to data science",
    "section": "2.4 References",
    "text": "2.4 References\n\n\n\n\nIoannidis, John P. A. 2005. “Why Most Published Research Findings Are False.” Journal Article. PLOS Medicine 2 (8): e124. https://doi.org/10.1371/journal.pmed.0020124.\n\n\nLeek, J. T., and R. D. Peng. 2015. “Statistics: P Values Are Just the Tip of the Iceberg.” Journal Article. Nature 520 (7549): 612. https://doi.org/10.1038/520612a.\n\n\nPeng, R. D., F. Dominici, and S. L. Zeger. 2006. “Reproducible Epidemiologic Research.” Journal Article. Am J Epidemiol 163 (9): 783–89. https://doi.org/10.1093/aje/kwj093.\n\n\nSpiegelhalter, D. J. 2019. The Art of Statistics : How to Learn from Data. Book. First US edition. New York: Basic Books."
  },
  {
    "objectID": "02-spreadsheets.html#cells-and-simple-functions",
    "href": "02-spreadsheets.html#cells-and-simple-functions",
    "title": "3  Storing data in spreadsheets",
    "section": "3.1 Cells and simple functions",
    "text": "3.1 Cells and simple functions\nA spreadsheet consists of cells, these can contain values, such as text, numbers, formulas and functions. Cells may also be formatted with attributes such as color or text styles. Below is an example of some data entered in a spreadsheet.\n\n\n\n\n\nExample entries from an Excel spreadsheet\n\n\n\n\nCell B6 contains a simple formula: = C6 + D6. This formula adds cells C6 and D6 resulting in the sum, 8. In formulas, mathematical operators can be used (\\(+, -, \\times , \\div\\) ). Formulas can be also extended with inbuilt function such as showed in @ref(tab:excel-functions).\n\n(#tab:excel-functions) Often used functions in excel.\n\n\nFunction\nEnglish\nNorwegian\n\n\n\n\nSum\nSUM()\nSUMMER()\n\n\nAverage\nAVERAGE()\nGJENNOMSNITT()\n\n\nStandard deviation\nSTDEV.S()\nSTDEV.S()\n\n\nCount\nCOUNT()\nANTALL()\n\n\nIntercept\nINTERCEPT()\nSKJÆRINGSPUNKT()\n\n\nSlope\nSLOPE()\nSTIGNINGSTALL()\n\n\nIf\nIF()\nHVIS()\n\n\n\nThe sum, average and standard deviation and count are simple functions for summarizing data. Intercept and slope are both examples of functions used to get simple associations from to sets of numbers (based on a regression model). The if function is an example of a function that can be used to conditionally enter data in a cell. For example, IF cell A1 contains a certain number, then cell B1 should display another a specified text.\nWhen looking for tips and tricks online, you may come across functions for excel in other languages than what is installed on your computer. To translate functions, and for a full overview of functions included in Microsoft Excel, see this website en.excel-translator.de/."
  },
  {
    "objectID": "02-spreadsheets.html#tidy-data-and-data-storage",
    "href": "02-spreadsheets.html#tidy-data-and-data-storage",
    "title": "3  Storing data in spreadsheets",
    "section": "3.2 Tidy data and data storage",
    "text": "3.2 Tidy data and data storage\nHadley Wickham uses a quote from Tolstoy when describing the principle of tidy data (Wickham 2014). This quote is so famous that it has given name to a principle. The principle in turn comes in many variants but basically states that when something goes wrong, it can be wrong in multiple ways. But when it is right/correct/works/succeeds, it does so in only one way1. This principle can be applied to data sets. There are so many ways that formatting of data sets can be problematic, but a limited sets of principles makes it good.\n\n\n\n\n\nLeo Tolstoy at the time when he was (possibly) authoring Anna Karenina. (Source: https://en.wikipedia.org/wiki/Leo_Tolstoy)\n\n\n\n\nA tidy data set consists of values originating from observations and belonging to variables. A variable is a definition of the values based on attributes. An observation may consist of several variables (Wickham 2014).\nA tidy data set typically has got one observation per row and one variable per column. Let’s say that we want to collect data from a strength test. A participant (participant is a variable) in our study conducts tests before and after the intervention (time is a variable) in two exercises (exercise is a variable) and we record the maximal strength in kg (load is a variable). The data set will look something like in the table below (@ref(tab:tidy-data-example)).\n\n(#tab:tidy-data-example) Example of tidy data.\n\n\nParticipant\nTime\nExercise\nLoad\n\n\n\n\nBruce Wayne\npre\nBench press\n95\n\n\nBruce Wayne\npost\nBench press\n128\n\n\nBruce Wayne\npre\nLeg press\n180\n\n\nBruce Wayne\npost\nLeg press\n280\n\n\n\nAnother example contains variables that actually carries two pieces of information in one variable. We again did a strength test, this time as maximal isometric contractions and in each test consisted of two attempts. We record this in two different variables, attempt 1 and 2. The resulting data set could look something like in Table @ref(tab:tidy-data-example-2).\n\n(#tab:tidy-data-example-2) Another example of tidy data.\n\n\nParticipant\nTime\nExercise\nAttempt1\nAttempt2\n\n\n\n\nSelina Kyle\npre\nIsometric\n81.3\n92.5\n\n\nSelina Kyle\npost\nIsometric\n97.1\n114.1\n\n\n\nTo make this data set tidy we need to extract the attempt information and record it in another variable as seen in Table @ref(tab:tidy-data-example-3).\n\n(#tab:tidy-data-example-3) A third example of tidy data.\n\n\nParticipant\nTime\nExercise\nAttempt\nload\n\n\n\n\nSelina Kyle\npre\nIsometric\n1\n81.3\n\n\nSelina Kyle\npre\nIsometric\n2\n92.5\n\n\nSelina Kyle\npost\nIsometric\n1\n97.1\n\n\nSelina Kyle\npost\nIsometric\n2\n114.1\n\n\n\nThis naturally gives additional rows to the data set. This is sometimes referred to as “long format” data as opposed to the structure where each attempt is given separate variables, something that is called “wide format”. You will notice during the course that for most purposes, the long format is most convenient. This is true when we create graphs and do statistical modelling. But sometimes a variable needs to be structured in a wide format to allow for certain operations.\nIf we follow what is recommended by Broman and Woo (Broman and Woo 2018), it is clear that each cell in a spreadsheet should only contain one value. If we for example decide to format a cell to a certain color, we add data to that cell on top of the actual data. You might add color to a cell in order to remember to add or change data. However, when you use the data set in other software, this information is lost. You should instead add another variable to allow for such data to be properly recorded. Using a variable called comments you can add text thta actually describes some information about that particular observation, information that is not lost when you use the data set in another software."
  },
  {
    "objectID": "02-spreadsheets.html#recording-data",
    "href": "02-spreadsheets.html#recording-data",
    "title": "3  Storing data in spreadsheets",
    "section": "3.3 Recording data",
    "text": "3.3 Recording data\nA trade secret2 from people who work all day with data and programming is that they are lazy. Lazy in the sense that you do not want to type too much, and absolutely not use the computer mouse when it can be avoided. When recording data we can try to be lazy to. We can do this by shortening variable names and not e.g. using CAPITAL letters when entering text in data storage. After a hard day at the keyboard, you will be happy to write strtest instead of Strength Test. The extra effort of using two capital letters might be the thing to tip you over the edge3. However, we should not be too lazy either, variable names and values should “short, but meaningful” (Broman and Woo 2018).\n\n\n\n\n\nD-FENS Foster gets pushed over the edge (Source: https://en.wikipedia.org/wiki/Falling_Down)\n\n\n\n\nData and variables should also be consistent. Do not mix data type, use a consistent way of entering e.g. dates and time, do not uses spaces or special characters. To enforce this you might want start your data collection with writing up a data dictionary that describes all variables you are collection. The dictionary can set the rules for your variables. This dictionary can also guide your data validation.\nIn Excel, data validation can be used to set rules for data entry. For example, if you have a numeric variable, you can set Excel only to accept numbers in specified set of cells. This makes it harder to enter erroneous data."
  },
  {
    "objectID": "02-spreadsheets.html#saving-data",
    "href": "02-spreadsheets.html#saving-data",
    "title": "3  Storing data in spreadsheets",
    "section": "3.4 Saving data",
    "text": "3.4 Saving data\nData from spreadsheets can be saved as special spreadsheet files, such as .xlsx. This format allows for functions, multiple spreadsheets in the same file (tabs) and cell formatting. If you follow the tips described above and in (Broman and Woo 2018) you do not need this fancy format. Instead you can store your data as a .csv file. This format may be read and edited with Excel (or another spreadsheet software) but also in a plain text editor. Data entered in this format (comma-separated values; csv) can look like this in a text editor:\n Participant;Time;Exercise;Attempt;load\n Selina Kyle;pre;Isometric;1;81.3  \n Selina Kyle;pre;Isometric;2;92.5\n Selina Kyle;post;Isometric;1;97.1\n Selina Kyle;post;Isometric;2;114.1\nThis is actually quite nice. The data takes little space, the simple format requires that data is well documented using e.g. a data dictionary and it is available for many other softwares as the format is simple. The data can be documented using a README file that could describe the purpose and methods of data collection, how the data is structured and what kind of data the variables contains. A simple README file can be written in a text editor such as Notepad and saved as a .txt file. Later in this course we will introduce a “markup” language often used to create README files containing a syntax that formats the text to a more pleasant style when converted to other formats."
  },
  {
    "objectID": "02-spreadsheets.html#footnotes",
    "href": "02-spreadsheets.html#footnotes",
    "title": "3  Storing data in spreadsheets",
    "section": "",
    "text": "See https://en.wikipedia.org/wiki/Anna_Karenina_principle↩︎\nA trade secret as in “not generally known to the public”. See en.wikipedia.org/wiki/Trade_secret.↩︎\nIn the movie Falling Down, Michael Douglas plays a unemployed engineer who gets push over edge, would it have been enough with a few to many capital letters?↩︎"
  },
  {
    "objectID": "02-spreadsheets.html#references",
    "href": "02-spreadsheets.html#references",
    "title": "3  Storing data in spreadsheets",
    "section": "3.5 References",
    "text": "3.5 References\n\n\n\n\nBroman, Karl W., and Kara H. Woo. 2018. “Data Organization in Spreadsheets.” Journal Article. The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989.\n\n\nStephen, G. Powell, R. Baker Kenneth, and Lawson Barry. 2009. “Errors in Operational Spreadsheets.” Journal Article. Journal of Organizational and End User Computing (JOEUC) 21 (3): 24–36. https://doi.org/10.4018/joeuc.2009070102.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal Article. Journal of Statistical Software; Vol 1, Issue 10 (2014). https://www.jstatsoft.org/v059/i10.\n\n\nZiemann, Mark, Yotam Eren, and Assam El-Osta. 2016. “Gene Name Errors Are Widespread in the Scientific Literature.” Journal Article. Genome Biology 17 (1): 177. https://doi.org/10.1186/s13059-016-1044-7."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science)",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites"
  }
]